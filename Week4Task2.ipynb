{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb2c80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing message 1/10\n",
      "\n",
      "==================================================\n",
      "Original Message: ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\n",
      "\n",
      "ğŸ“ŒSaachi Electric Kettle\n",
      "\n",
      "ğŸ‘Borosilicate Glass Body\n",
      "ğŸ‘Overheat protection\n",
      "ğŸ‘Automatic switch off\n",
      "ğŸ‘2200w\n",
      "\n",
      "á‹‹áŒ‹á¦Â  ğŸ’²ğŸ· 2700Â  á‰¥áˆ­ âœ…\n",
      "\n",
      "â™¦ï¸á‹áˆµáŠ• ááˆ¬ áŠá‹ á‹«áˆˆá‹ğŸ”¥ğŸ”¥ğŸ”¥\n",
      "\n",
      "ğŸ¢ áŠ á‹µáˆ«áˆ»ğŸ‘‰\n",
      "\n",
      "ğŸ“â™¦ï¸#áˆ˜áŒˆáŠ“áŠ›_áˆ˜áˆ°áˆ¨á‰µ_á‹°á‹áˆ­_áˆáˆ_áˆáˆˆá‰°áŠ›_áá‰… á‰¢áˆ® á‰. S05/S06\n",
      "\n",
      "\n",
      "Â Â Â Â  ğŸ’§ğŸ’§ğŸ’§ğŸ’§\n",
      "\n",
      "\n",
      "Â Â Â  ğŸ“² 0902660722\n",
      "Â Â Â  ğŸ“² 0928460606 \n",
      "\n",
      "ğŸ”–\n",
      "ğŸ’¬á‰ Telegram áˆˆáˆ›á‹˜á‹ â¤µï¸ á‹­áŒ á‰€áˆ™ğŸ”½\n",
      "\n",
      "@zemencallcenter \n",
      "\n",
      "@zemenexpressadmin\n",
      "\n",
      "áˆˆá‰°áŒ¨áˆ›áˆª áˆ›á‰¥áˆ«áˆªá‹« á‹¨á‰´áˆŒáŒáˆ«áˆ áŒˆáƒá‰½áŠ•â¤µï¸\n",
      "https://telegram.me/zemenexpress\n",
      "\n",
      "ğŸ’¥ğŸ’¥...................................ğŸ’¥ğŸ’¥\n",
      "--------------------------------------------------------------------------------\n",
      "Tokens: ................................... Saachi Electric Kettle Borosilicate Glass Body Overheat protection Automatic switch off 2200w á‹‹áŒ‹á¦ 2700 á‰¥áˆ­ á‹áˆµáŠ• ááˆ¬ áŠá‹ á‹«áˆˆá‹ áŠ á‹µáˆ«áˆ» áˆ˜áŒˆáŠ“áŠ›_áˆ˜áˆ°áˆ¨á‰µ_á‹°á‹áˆ­_áˆáˆ_áˆáˆˆá‰°áŠ›_áá‰… á‰¢áˆ® á‰. S05S06 0902660722 0928460606 á‰ Telegram áˆˆáˆ›á‹˜á‹ á‹­áŒ á‰€áˆ™ zemencallcenter zemenexpressadmin áˆˆá‰°áŒ¨áˆ›áˆª áˆ›á‰¥áˆ«áˆªá‹« á‹¨á‰´áˆŒáŒáˆ«áˆ áŒˆáƒá‰½áŠ• httpstelegram.mezemenexpress ...................................\n",
      "\n",
      "----------------------------------------\n",
      "Context: . . .\n",
      "Current Token (1/363): '.'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# Load your scraped dataset\n",
    "df = pd.read_csv('C:\\\\Users\\\\Hiwi\\\\Documents\\\\week4\\\\all_telegram_messages.csv')\n",
    "def clean_amharic_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"  # skip non-string entries\n",
    "    text = re.sub(r'[^\\w\\s\\u1200-\\u137F.,!?á¡á¢á£]', '', text)\n",
    "    replacements = {\n",
    "        '::': 'á¢',\n",
    "        ':': 'á¡',\n",
    "        ',': 'á£'\n",
    "    }\n",
    "    for k, v in replacements.items():\n",
    "        text = text.replace(k, v)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = unicodedata.normalize('NFC', text)\n",
    "    return text\n",
    "# Remove emojis\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U0001F300-\\U0001F5FF\"\n",
    "        u\"\\U0001F680-\\U0001F6FF\"\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub('', text)\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "# Define your labeling function\n",
    "def label_message(message, tokens):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Original Message: {message}\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"Tokens: {tokens}\")\n",
    "    \n",
    "    labels = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        valid_labels = ['B-PROD', 'I-PROD', 'B-LOC', 'I-LOC', 'B-PRICE', 'I-PRICE', 'O']\n",
    "        \n",
    "        # Show context tokens\n",
    "        context_start = max(0, i-2)\n",
    "        context_end = min(len(tokens), i+3)\n",
    "        context = tokens[context_start:context_end]\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*40)\n",
    "        print(f\"Context: {' '.join(context)}\")\n",
    "        print(f\"Current Token ({i+1}/{len(tokens)}): '{token}'\")\n",
    "        \n",
    "        while True:\n",
    "            label = input(\"Label: \").strip().upper()\n",
    "            if label in valid_labels:\n",
    "                labels.append((token, label))\n",
    "                break\n",
    "            print(f\"Invalid label! Please use one of: {', '.join(valid_labels)}\")\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Define function to save to CoNLL format\n",
    "def save_to_conll(labeled_data, output_path):\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for original_msg, annotations in labeled_data:\n",
    "            for token, label in annotations:\n",
    "                f.write(f\"{token}\\t{label}\\n\")\n",
    "            f.write(\"\\n\")  # Blank line between messages\n",
    "    print(f\"Saved {len(labeled_data)} messages to {output_path}\")\n",
    "\n",
    "# Precompute tokens for all messages\n",
    "df['tokens'] = df['text'].apply(clean_amharic_text)\n",
    "\n",
    "# Select messages to label (first 10)\n",
    "messages_to_label = df.head(10)\n",
    "\n",
    "labeled_data = []\n",
    "for idx, row in messages_to_label.iterrows():\n",
    "    message = row['text']\n",
    "    tokens = row['tokens']\n",
    "    \n",
    "    print(f\"\\nProcessing message {idx+1}/{len(messages_to_label)}\")\n",
    "    annotations = label_message(message, tokens)\n",
    "    labeled_data.append((message, annotations))\n",
    "    \n",
    "    print(f\"Message labeled! ({len(labeled_data)}/{len(messages_to_label)} done)\")\n",
    "\n",
    "print(f\"\\nSuccessfully labeled {len(labeled_data)} messages!\")\n",
    "\n",
    "# Now save to CoNLL format\n",
    "save_to_conll(labeled_data, \"my_labeled_dataset.conll\")\n",
    "\n",
    "# Verify the output\n",
    "print(\"\\nPreview of labeled data:\")\n",
    "with open(\"my_labeled_dataset.conll\", 'r', encoding='utf-8') as f:\n",
    "    print(f.read(500))  # Print first 500 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6adf45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
